{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Statement\n",
    "\n",
    "# Project Statement\n",
    "\n",
    "- Create a Jupyter notebook\n",
    "- Create a data set by simulating a real-world phenomenon of my choosing \n",
    "- Model and synthesise such data using Python (suggest to use the numpy.random package for this purpose)\n",
    "- Choose a real-world phenomenon that can be measured and for which you could collect at least one-hundred data points across at least four different variables.\n",
    "- Investigate the types of variables involved, their likely distributions, and their relationships with each other.\n",
    "- Synthesise/simulate a data set as closely matching their properties as possible.\n",
    "- Detail your research and implement the simulation in a Jupyter notebook â€“ the data set itself can simply be displayed in an output cell within the notebook.\n",
    "\n",
    "# Introduction\n",
    "\n",
    "A computer simulation is an application designed to imitate a real-life situation with advanages of \n",
    "\n",
    "- It can avoid danger and loss of life.\n",
    "- Conditions can be varied and outcomes investigated.\n",
    "- Critical situations can be investigated without risk.\n",
    "- It is cost effective.\n",
    "- Simulations can be sped up so behaviour can be studied easily over a long period of time.\n",
    "- Simulations can be slowed down to study behaviour more closely [1]\n",
    "\n",
    "The project is to simulate a real-world phenomenon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Framingham Heart Study \n",
    "\n",
    "The Framingham Heart Study is now considered one of the longest, most important epidemiological studies in medical history. In the 1960s, the study demonstrated the role cigarette smoking plays in the development of heart disease. Those findings helped to fuel the first anti-smoking campaigns of that era. The study provided researchers with knowledge of how dietary fat can increase the risk of heart disease. It showed a link between cholesterol levels in the blood and an individual's risk for developing heart disease. Later, Framingham data also demonstrated the beneficial role of high-density lipoprotein (HDL) cholesterol and the negative consequences of low-density lipoprotein (LDL) cholesterol. This program has helped to educate physicians, patients, and the public about the dangers of high blood cholesterol and to bring about reductions in Americans' blood cholesterol levels. [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "Import the modules required for project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the Framingham Heart Data to reporduce real-world dataset\n",
    "Import the Framingham Heart Data and print out the first 10 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from data folder\n",
    "# https://github.com/TarekDib03/Analytics/blob/master/Week3%20-%20Logistic%20Regression/Data/framingham.csv\n",
    "df = pd.read_csv(\"data/framingham.csv\")\n",
    "\n",
    "# Print first 10 entries\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up data\n",
    "\n",
    "To begin the cleanig of data df.describe() will output the count, mean, std, min, max as well as lower, 50 and upper percentiles the lower (25) and upper (75) percentiles. The 50 percentile is the same as the median. [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the count, mean, std, min, max as well as lower, 50 and upper percentiles. \n",
    "# The lower (25) and upper (75) percentiles. The 50 percentile is the same as the median.\n",
    "# This is to give an overview of the dataset including missing values\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe has 16 rows for the purpose of the project we require a minimum four different variables. To select the variables required for the project a correlation matrix investigates the dependence between multiple variables at the same time. It shows symmetric tabular data where each row and column represent a variable, and the corresponding value is the correlation coefficient denoting the strength of a relationship between these two variables. [5]\n",
    "\n",
    "Using TenYearCHD (10 year risk of coronary heart disease(CHD)) we are going to identify the variables and the strength of a relationship with the other variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select the variables required for the project A correlation matrix investigates the dependency \n",
    "# between multiple variables at the same time. It shows symmetric tabular data where each row and column \n",
    "# represent a variable, and the corresponding value is the correlation coefficient denoting the strength of a \n",
    "# relationship between these two variables. \n",
    "# https://www.geeksforgeeks.org/sort-correlation-matrix-in-python/\n",
    "# [9]\n",
    "\n",
    "print('Get correlation of variables with TenYearCHD')\n",
    "FHS_correlation = df.corr()['TenYearCHD']\n",
    "corr_FHS = FHS_correlation.abs().sort_values(ascending=False)[1:]\n",
    "round(corr_FHS,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new dataframe is create using varibales with the highest correlation of 10% and above. This ensure we have selected more than the four variables\n",
    "\n",
    "'TenYearCHD','age','sysBP','prevalentHyp','diaBP','glucose', 'diabetes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with variables with the highest correlation\n",
    "# Cut-off rate is 10% and above\n",
    "\n",
    "print('New dataframe with values with highest correlation')\n",
    "High_corr = df[['TenYearCHD','age','sysBP','prevalentHyp','diaBP','glucose', 'diabetes']] \n",
    "High_corr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Group1 = High_corr.loc[((High_corr['age'] > 40) & (High_corr['age'] <= 50))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count missing values in rows by applying the Pandas isna() function with the sum() function to get the counts of missing values per each column in the dataframe. [6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in rows\n",
    "# https://cmdlinetips.com/2020/11/how-to-get-number-of-missing-values-in-each-column-in-pandas/\n",
    "print('Count Missing values in dataframe')\n",
    "High_corr.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the project only requires more one-hundred data points across a decision to drop all rows containing the blank values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with blank values\n",
    "# https://statisticsglobe.com/drop-rows-blank-values-from-pandas-dataframe-python\n",
    "print('Check cleaned data')\n",
    "High_corr.dropna(inplace = True)                   \n",
    "High_corr.describe()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check rows are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Verify missing values are removed from dataframe')\n",
    "High_corr.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the rows [9]\n",
    "High_corr = High_corr.rename(columns = {'TenYearCHD' : 'At Risk',\n",
    "                            'age' : 'Age',\n",
    "                            'sysBP' : 'Systolic Blood Pressure',\n",
    "                            'prevalentHyp' : 'Hypertensive',\n",
    "                            'diaBP' : 'Diastolic Blood Pressure',\n",
    "                            'glucose' : 'Glucose Levels',\n",
    "                            'diabetes' : 'Diabetes'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Histograms using numpy.random.normal.html\n",
    "\n",
    "https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get age groups \n",
    "# https://stackoverflow.com/questions/64900985/pandas-count-number-of-occurrences-of-each-value-between-ranges\n",
    "High_corr['Age'].value_counts(bins=[0,40,50,60,70], normalize=True).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Group0 = High_corr.loc[(High_corr['Age'] <= 40)]\n",
    "Group1 = High_corr.loc[((High_corr['Age'] > 40) & (High_corr['Age'] <= 50))]\n",
    "Group2 = High_corr.loc[((High_corr['Age'] > 50) & (High_corr['Age'] <= 60))]\n",
    "Group3 = High_corr.loc[((High_corr['Age'] > 60) & (High_corr['Age'] <= 70))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.webmd.com/hypertension-high-blood-pressure/guide/diastolic-and-systolic-blood-pressure-know-your-numbers\n",
    "\n",
    "Hereâ€™s how to understand your systolic blood pressure number:\n",
    "\n",
    "    Normal: Below 120\n",
    "    Elevated: 120-129\n",
    "    Stage 1 high blood pressure (also called hypertension): 130-139\n",
    "    Stage 2 hypertension: 140 or more\n",
    "    Hypertensive crisis: 180 or more. Call 911.\n",
    "\n",
    "This is what your diastolic blood pressure number means:\n",
    "\n",
    "    Normal: Lower than 80\n",
    "    Stage 1 hypertension: 80-89\n",
    "    Stage 2 hypertension: 90 or more\n",
    "    Hypertensive crisis: 120 or more.\n",
    "\n",
    "https://academic.oup.com/aje/article/163/4/342/103626\n",
    "\n",
    "glucose categories: normal (â‰¤5.55 mmol/liter (100 mg/dl)), \n",
    "impaired (5.56â€“6.99 mmol/liter (101â€“126 mg/dl)), and diabetic \n",
    "(>6.99 mmol/liter (>126 mg/dl))\n",
    "\n",
    "# systolic blood pressure\n",
    "# Normal <= 120\n",
    "# Elevated 120 - 180\n",
    "# Hypertensive >= 180\n",
    "\n",
    "# diastolic blood pressure\n",
    "# Normal <= 80\n",
    "# Elevated 80 - 120\n",
    "# Hypertensive >= 120\n",
    "\n",
    "# glucose levels\n",
    "# normal <= 100\n",
    "# impaired 101 - 126\n",
    "# diabetic > 126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age groups \n",
    "# https://stackoverflow.com/questions/35523635/extract-values-in-pandas-value-counts\n",
    "# Group0['Systolic Blood Pressure'].value_counts(bins=[0,120,180,295], normalize=True).sort_index().tolist()\n",
    "# Group0['Diastolic Blood Pressure'].value_counts(bins=[0,80,120,142], normalize=True).sort_index()\n",
    "# Group0['Glucose Levels'].value_counts(bins=[0,100,126,394], normalize=True).sort_index()\n",
    "\n",
    "agegroups = ['Group0', 'Group0', 'Group0','Group0']\n",
    "\n",
    "for ages in agegroups:\n",
    "    SBP = ages['Systolic Blood Pressure'].value_counts(bins=[0,120,180,295], normalize=True).sort_index().tolist()\n",
    "    DBP = ages['Diastolic Blood Pressure'].value_counts(bins=[0,80,120,142], normalize=True).sort_index().tolist()\n",
    "    GL = ages['Glucose Levels'].value_counts(bins=[0,100,126,394], normalize=True).sort_index().tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Group0['Diastolic Blood Pressure'].value_counts(bins=[0,80,120,142], normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Group0['Glucose Levels'].value_counts(bins=[0,100,126,394], normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References \n",
    "\n",
    "[1] https://www.bbc.co.uk/bitesize/guides/zvxp34j/revision/3\n",
    "\n",
    "[2] https://nfb.org//sites/default/files/images/nfb/publications/vodold/vspr9804.htm\n",
    "\n",
    "[3] https://github.com/TarekDib03/Analytics/blob/master/Week3%20-%20Logistic%20Regression/Data/framingham.csv\n",
    "\n",
    "[4] https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html\n",
    "\n",
    "[5] https://www.geeksforgeeks.org/sort-correlation-matrix-in-python/\n",
    "\n",
    "[6] https://cmdlinetips.com/2020/11/how-to-get-number-of-missing-values-in-each-column-in-pandas/\n",
    "\n",
    "[7] https://statisticsglobe.com/drop-rows-blank-values-from-pandas-dataframe-python\n",
    "\n",
    "[8] https://towardsdatascience.com/visualizing-data-with-pair-plots-in-python-f228cf529166\n",
    "\n",
    "[9] https://www.kaggle.com/micahshull/python-heart-disease-framingham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
